{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Reward extraction: Experiment 1_\n",
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Reward extraction using C3D network and KTH dataset <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, MaxPooling2D, Input, Concatenate,MaxPooling3D, Reshape, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "## Custom scripts\n",
    "import lscript as lsp\n",
    "import dataset as dset\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Defining variables\n",
    "time_step=50 # Sequence length\n",
    "imagefolderpath= ('/nobackup/leopauly/KTH_new/') # Folder path where the video sequences are stored\n",
    "print(os.path.isdir(imagefolderpath)) # Checking if directory of video dataset exists\n",
    "LOG_DIR='./logdir'\n",
    "custom_global_step=0\n",
    "nb_classes=3\n",
    "lr_rate=.0005\n",
    "batch_size = 5\n",
    "height=150\n",
    "width=300\n",
    "channel=1\n",
    "lstm_h_units=10\n",
    "cluster_length=2\n",
    "num_clusters=25\n",
    "feature_size=487\n",
    "extraction_batch_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining placeholders in tf\n",
    "data = tf.placeholder(tf.float32, [None, cluster_length, height, width, channel]) #step_size=No: of frames in video sequence\n",
    "target = tf.placeholder(tf.float32, [None, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 150, 300, 1)    0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv3D)               (None, 2, 150, 300, 64)   1792      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 2, 75, 150, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 2, 75, 150, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 1, 37, 75, 128)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 355200)            0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 487)               172982887 \n",
      "=================================================================\n",
      "Total params: 173,205,991\n",
      "Trainable params: 173,205,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Suggested Network structure: Conv3D followed by LSTM\n",
    "model=md.modelC3D(cluster_length, height, width, channel, load_weights=False)\n",
    "feature_out=model([data])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 2, 150, 300, 1)\n",
      "shape of clustered demo data: (25, 2, 150, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "## Splitting into clusters the video of source demonstration\n",
    "x_demo,y_demo=dset.batch_gen_train(nb_classes,extraction_batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "x_demo_original=x_demo\n",
    "x_demo =x_demo.reshape(x_demo.shape[0],x_demo.shape[1],height,width,channel)\n",
    "clusters_demo=dset.cluster_generator(x_demo,num_clusters,cluster_length,height,width,channel)\n",
    "\n",
    "## Extraction of features\n",
    "print('shape of clustered demo data:',clusters_demo.shape)\n",
    "features_demo=np.zeros([num_clusters,feature_size])\n",
    "for i in range(num_clusters):\n",
    "    t=clusters_demo[i].reshape(1,cluster_length,height,width,channel)\n",
    "    features_demo[i]= sess.run(feature_out,feed_dict={data:t})\n",
    "    #print(features)\n",
    "print('shape of features from robot actions: ',features_demo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into & displaying clusters of target actions\n",
    "x_robo,y_robo=dset.batch_gen_train(nb_classes,extraction_batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "x_robo_original=x_robo\n",
    "x_robo =x_robo.reshape(x_robo.shape[0],x_robo.shape[1],height,width,channel)\n",
    "clusters_robo=dset.cluster_generator(x_robo,num_clusters,cluster_length,height,width,channel)\n",
    "\n",
    "## Extracting features\n",
    "print('shape of clustered robot data:',clusters_robo.shape)\n",
    "features_robo=np.zeros([num_clusters,feature_size])\n",
    "for i in range(num_clusters):\n",
    "    t=clusters_robo[i].reshape(1,cluster_length,height,width,channel)\n",
    "    features_robo[i]= sess.run(feature_out,feed_dict={data:t})\n",
    "    #print(features)\n",
    "print('shape of features from robot actions: ', features_robo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Extracting reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance=np.ones([num_clusters,feature_size])\n",
    "reward=np.ones([num_clusters,1])\n",
    "for i in range(num_clusters):\n",
    "    distance[i] = features_demo[i]-features_robo[i]\n",
    "    reward[i]=-(np.linalg.norm(distance[i]))\n",
    "#print(reward)\n",
    "#print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vlaues=list((range(num_clusters)))\n",
    "lsp.plot_values_with_legends(y_vlaues,reward,'reward','clusters','value','reward function',color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id=8\n",
    "## Clusters from demos\n",
    "y_d=np.repeat(y_demo,num_clusters) \n",
    "display=clusters_demo.reshape(clusters_demo.shape[0],clusters_demo.shape[1],clusters_demo.shape[2],clusters_demo.shape[3])\n",
    "lsp.view_video_seq(display,y_d,cluster_length,cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters from robot action\n",
    "y_r=np.repeat(y_robo,num_clusters) \n",
    "display=clusters_robo.reshape(clusters_robo.shape[0],clusters_robo.shape[1],clusters_robo.shape[2],clusters_robo.shape[3])\n",
    "lsp.view_video_seq(display,y_r,cluster_length,cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrations / Source Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsp.view_video_seq(x_demo_original,y_demo,time_step,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robot / Target actions Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsp.view_video_seq(x_robo_original,y_robo,time_step,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
