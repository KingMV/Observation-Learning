{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Activity feature extractor_\n",
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : For extracting action features from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, MaxPooling2D, Input, Concatenate\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import keras\n",
    "\n",
    "## Custom scripts\n",
    "import lscript as lsp\n",
    "import dataset as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Defining variables\n",
    "time_step=50 # Number of frames to be skipped\n",
    "imagefolderpath= ('/nobackup/leopauly/KTH_new/') # Folder pathe where the video sequences are stored\n",
    "print(os.path.isdir(imagefolderpath)) # Checking if directory of video dataset exists\n",
    "LOG_DIR='./logdir'\n",
    "custom_global_step=0\n",
    "hidden_num = 24 # Number of neurons in hidden layer of LSTM\n",
    "nb_classes=3\n",
    "lr_rate=.0005\n",
    "batch_size = 20\n",
    "nb_seq_train=360\n",
    "no_of_batches = int(nb_seq_train / batch_size)\n",
    "epoch = 5\n",
    "height=150\n",
    "width=300\n",
    "channel=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and displaying data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img=cv2.imread(str(imagefolderpath+'/'+str(1)+'/'+str(1)+'.png'),0)\n",
    "print(img.shape)\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make display like an animation\n",
    "x,y=dset.batch_gen_train(nb_classes,batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "item_num=19\n",
    "lsp.view_video_seq(x,y,time_step,item_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining placeholders in tf\n",
    "data_1 = tf.placeholder(tf.float32, [None, time_step, height, width, channel]) #step_size=No: of frames in video sequence\n",
    "data_2 = tf.placeholder(tf.float32, [None, time_step, height, width, channel])\n",
    "data_3 = tf.placeholder(tf.float32, [None, time_step, height, width, channel])\n",
    "target = tf.placeholder(tf.float32, [None, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1] Defining the model in keras using functional layers\n",
    "input_1 = Input(shape=(None, height, width, channel))\n",
    "input_2 = Input(shape=(None, height, width, channel))\n",
    "input_3 = Input(shape=(None, height, width, channel))\n",
    "\n",
    "conv3D=Conv3D(filters=1, kernel_size=(3,3,3),padding='same')\n",
    "layer1_1=conv3D(inputs=input_1)\n",
    "layer1_2=conv3D(inputs=input_1)\n",
    "layer1_3=conv3D(inputs=input_1)\n",
    "\n",
    "concatenated = keras.layers.concatenate([layer1_1, layer1_2,layer1_3])\n",
    "model_out=ConvLSTM2D(filters=1, kernel_size=(5, 5),padding='valid', return_sequences=True)(concatenated)\n",
    "\n",
    "model=Model([input_1,input_2,input_3],model_out)\n",
    "inter_out=model([data_1,data_2,data_3])\n",
    "print(model.summary())\n",
    "\n",
    "layer2=tf.nn.max_pool3d(inter_out,ksize=(1,1,4,4,1),strides=(1,1,4,4,1),padding='VALID')\n",
    "size1=tf.size(layer2)\n",
    "shape1=tf.shape(layer2)\n",
    "fc = tf.reshape(layer2,[batch_size, 133200]) #shape1[1]*shape1[2]*shape1[3]*shape1[4]])  #138750\n",
    "#shape2=tf.shape(fc)\n",
    "out=tf.layers.dense(fc,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "\n",
    "x,y=dset.batch_gen_train(nb_classes,batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "x =x.reshape(x.shape[0],x.shape[1],height,width,channel)\n",
    "y_onehot = lsp.one_hot(y,nb_classes)\n",
    "print(sess.run([out],{data_1: x,data_2:x,data_2:x, target: y_onehot}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions= tf.nn.softmax(out)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target,logits=out))\n",
    "optimizer = tf.train.AdamOptimizer(lr_rate)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(predictions, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "\n",
    "# Defining variables for writing summary\n",
    "tf.summary.histogram(\"predictions\",predictions )\n",
    "tf.summary.scalar(\"cross_entropy\",cross_entropy )\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO : make data generater to generate class also\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "train_writer = tf.summary.FileWriter('./logdir', sess.graph)\n",
    "\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for iteration in range(no_of_batches):\n",
    "        #x=dset.batch_gen(0+(batch_size*iteration),batch_size+(batch_size*iteration),batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "        x,y=dset.batch_gen_train(nb_classes,batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "        x =x.reshape(x.shape[0],x.shape[1],height,width,channel)\n",
    "        y_onehot = lsp.one_hot(y,nb_classes)\n",
    "        #print(x.shape,y.shape)\n",
    "        \n",
    "        summ_string,_=sess.run([summary_op,minimize],{data: x, target: y_onehot})\n",
    "        train_writer.add_summary(summ_string,custom_global_step+1) # Writing summary to disc\n",
    "        custom_global_step+=1\n",
    "        \n",
    "        print('Iteration {}'.format(iteration))\n",
    "    print ('Epoch {}'.format(str(i)))\n",
    "\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y=dset.batch_gen_test(nb_classes,batch_size,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "x =x.reshape(x.shape[0],x.shape[1],height,width,channel)\n",
    "y_onehot = lsp.one_hot(y,nb_classes)\n",
    "\n",
    "img=x[12]\n",
    "print(img.shape)\n",
    "img=img.reshape(1,img.shape[0],height,width,channel)\n",
    "print(img.shape)\n",
    "y_=np.zeros([1,nb_classes])\n",
    "units = sess.run(inter_out,feed_dict={data:img, target:y_})\n",
    "print(units.shape)\n",
    "units=units.reshape(units.shape[1],units.shape[2])\n",
    "print(units.shape)\n",
    "plt.imshow(units)\n",
    "plt.gray()\n",
    "plt.savefig('./results/result6.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession() \n",
    "saved_model = tf.train.import_meta_graph('./logdir/model.ckpt.meta')\n",
    "saved_model.restore(sess, tf.train.latest_checkpoint('./logdir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img=x[1]\n",
    "print(img.shape)\n",
    "img=img.reshape(1,img.shape[0],height,width,channel)\n",
    "print(img.shape)\n",
    "y_=np.zeros([1,nb_classes])\n",
    "units = sess.run(inter_out,feed_dict={data:img, target:y_})\n",
    "print(units.shape)\n",
    "units=units.reshape(units.shape[1],units.shape[2])\n",
    "print(units.shape)\n",
    "plt.imshow(units)\n",
    "plt.gray()\n",
    "plt.savefig('./results/result3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#TODO: Create a test_batch_generator\n",
    "\n",
    "test=dset.batch_gen(0,2,2,time_step,height,width,channel,imagefolderpath,gray=True)\n",
    "print(img.shape)\n",
    "img=test[1]\n",
    "img=img.reshape(1,img.shape[1],height,width,channel)\n",
    "\n",
    "units = sess.run(inter_out,feed_dict={data:img})\n",
    "units=units.reshape(units.shape[1],units.shape[2])\n",
    "lsp.view_image(units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking the items in the log directory\n",
    "!tensorboard --inspect --logdir='./logdir/'\n",
    "\n",
    "# Running tensorflow\n",
    "print('If on windows system go to: http://localhost:6006')\n",
    "!tensorboard --logdir='./logdir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
