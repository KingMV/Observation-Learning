{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. C3D+ucf_model_training_multigpu\n",
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Training the C3D model using UCF 101 action recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from scipy.ndimage import imread\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md\n",
    "#from DataSet.DataSet import DataSet\n",
    "import dataset as dset\n",
    "import ucf101_dataset as ucf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "cluster_length=16\n",
    "nb_classes=101\n",
    "\n",
    "lr_rate=.001\n",
    "next_batch_start=0\n",
    "batch_size=8\n",
    "total_train_videos=9999\n",
    "memory_batch_size_train=9999\n",
    "memory_batch_size_test=3000\n",
    "batch_size=8\n",
    "iterations= (int(total_train_videos/memory_batch_size_train)) #10001\n",
    "#epoch=int((memory_batch_size_train/batch_size)*10)\n",
    "custom_global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding how many devices are available\n",
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "num_gpus = len(gpus)\n",
    "print(\"GPU nodes found: \" + str(num_gpus))\n",
    "print('Avaialble gpsu:',str(gpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding how many CPUs are available\n",
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'CPU']\n",
    "num_gpus = len(gpus)\n",
    "print(\"CPU nodes found: \" + str(num_gpus))\n",
    "print('Avaialble cpus:',str(gpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel]) \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "y_true_cls = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the network in a model function, to make parallelisation across GPUs easier.\n",
    "def model(x_image_, y_true_):\n",
    "    ''' Expecting the following parameters, in batches:\n",
    "        x_image_ - x_image batch\n",
    "        y_true_ - y_true batch\n",
    "    '''\n",
    "\n",
    "    model = md.C3D_ucf101_training_model_tf(summary=False)\n",
    "    out=model(x_image_)\n",
    "    \n",
    "    y_pred = tf.nn.softmax(out)\n",
    "    y_pred_cls = tf.argmax(out, dimension=1)\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=out))\n",
    "    \n",
    "    # Outputs to be returned to CPU\n",
    "    return y_pred, y_pred_cls, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_parallel(fn, **kwargs):\n",
    "    in_splits = {}\n",
    "    for k, v in kwargs.items():\n",
    "        in_splits[k] = tf.split(v, num_gpus)\n",
    "\n",
    "    # An array for every aggregated output\n",
    "    y_pred_split, y_pred_cls_split, cost_split, fv_split = [], [], [], []\n",
    "    for i in range(num_gpus):\n",
    "        with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
    "            with tf.variable_scope(tf.get_variable_scope(), reuse=i > 0):\n",
    "                y_pred_, y_pred_cls_, cost_,  = fn(**{k : v[i] for k, v in in_splits.items()})\n",
    "                # Adding the output from each device.\n",
    "                y_pred_split.append(y_pred_)\n",
    "                y_pred_cls_split.append(y_pred_cls_)\n",
    "                cost_split.append(cost_)\n",
    "                #fv_split.append(fv_)\n",
    "\n",
    "    # Aggregating and returning outputs. tf.concat for multi-dimensional arrays; tf.stack if single values.\n",
    "    return tf.concat(y_pred_split, axis=0), tf.concat(y_pred_cls_split, axis=0),tf.stack(cost_split, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if num_gpus > 0:\n",
    "    # There is significant latency for CPU<->GPU copying of shared variables.\n",
    "    # We want the best balance between speedup and minimal latency.\n",
    "    y_pred, y_pred_cls, cost = make_parallel(model, x_image_=x_image, y_true_=y_true)\n",
    "else:\n",
    "    # CPU-only version\n",
    "    y_pred, y_pred_cls, cost = model(x_image_=x_image, y_true_=y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimisation calculated on CPU on aggregated results.\n",
    "# NEED the colocate_gradients_with_ops flag TRUE to get the gradient ops to run on same device as original op!\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=2e-4).minimize(cost, colocate_gradients_with_ops=True)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(iterations,epoch):\n",
    "    test_images, test_labels_cls, next_batch_start, _ = ucf.read_vid_and_label('./Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/UCF101_data_preparation/test.list',memory_batch_size_test,-1,16,112,normalisation=True)\n",
    "    test_labels=keras.utils.to_categorical(test_labels_cls, num_classes=nb_classes)\n",
    "    #print(test_images.shape)\n",
    "    #print(test_labels_cls)\n",
    "    test_score= sess.run([accuracy], feed_dict={x_image:test_images,y_true_cls:test_labels_cls,K.learning_phase(): 0 })    #print(next_batch_start)\n",
    "    print('Test accuracy after iteration:',iterations,',epoch:',epoch,'is:',test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "sess.run(init_op)\n",
    "saver = tf.train.Saver() # Creating tf.train.Saver() object\n",
    "\n",
    "for i in range(iterations*10):\n",
    "    train_images, train_labels_cls, next_batch_start, _ = ucf. read_vid_and_label('./Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/UCF101_data_preparation/train.list',memory_batch_size_train,-1,cluster_length,112,normalisation=True)\n",
    "    train_labels=keras.utils.to_categorical(train_labels_cls, num_classes=nb_classes)\n",
    "    for j in range(memory_batch_size_train/batch_size):\n",
    "        output_value = sess.run([optimizer], feed_dict={x_image:train_images[0*j:batch_size*j],y_true:train_labels[(batch_size*j):(batch_size*(j+1))],K.learning_phase(): 1 })    #print(next_batch_start)\n",
    "        if (iterations%1000):\n",
    "            saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), global_step=custom_global_step)\n",
    "            custom_global_step=custom_global_step+1\n",
    "            testing(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
